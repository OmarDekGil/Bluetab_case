{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79dbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, jarque_bera, anderson\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c7748",
   "metadata": {},
   "source": [
    "Estrategia de preprocesamiento de datos\n",
    "\n",
    "Dado que el objetivo del proyecto es predecir el nivel de engagement del jugador (Low, Medium, High) mediante clasificación multiclase, el preprocesamiento se orientará a preparar los datos de forma adecuada para distintos algoritmos de aprendizaje supervisado. La variable PlayerID será eliminada al no aportar información predictiva. Las variables categóricas (Gender, Location, GameGenre y GameDifficulty) se transformarán mediante One-Hot Encoding, permitiendo su uso en modelos como la regresión logística multiclase, Random Forest y otros clasificadores.\n",
    "\n",
    "Las variables numéricas serán escaladas utilizando StandardScaler, especialmente relevante para modelos sensibles a la escala como la regresión logística multiclase (One-vs-Rest o multinomial), que se utilizará como modelo baseline. No se aplicará eliminación sistemática de outliers, ya que estos representan comportamientos reales de jugadores intensivos. Finalmente, los datos se dividirán en conjuntos de entrenamiento y prueba mediante un split 80/20, integrando todo el flujo de transformación y modelado mediante Pipeline y ColumnTransformer de scikit-learn, garantizando reproducibilidad y evitando fugas de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d2df5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PlayerID', 'Age', 'Gender', 'Location', 'GameGenre', 'PlayTimeHours',\n",
      "       'InGamePurchases', 'GameDifficulty', 'SessionsPerWeek',\n",
      "       'AvgSessionDurationMinutes', 'PlayerLevel', 'AchievementsUnlocked',\n",
      "       'EngagementLevel'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40034 entries, 0 to 40033\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PlayerID                   40034 non-null  int64  \n",
      " 1   Age                        40034 non-null  int64  \n",
      " 2   Gender                     40034 non-null  object \n",
      " 3   Location                   40034 non-null  object \n",
      " 4   GameGenre                  40034 non-null  object \n",
      " 5   PlayTimeHours              40034 non-null  float64\n",
      " 6   InGamePurchases            40034 non-null  int64  \n",
      " 7   GameDifficulty             40034 non-null  object \n",
      " 8   SessionsPerWeek            40034 non-null  int64  \n",
      " 9   AvgSessionDurationMinutes  40034 non-null  int64  \n",
      " 10  PlayerLevel                40034 non-null  int64  \n",
      " 11  AchievementsUnlocked       40034 non-null  int64  \n",
      " 12  EngagementLevel            40034 non-null  object \n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 4.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "print(df.columns)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"PlayerID\", \"EngagementLevel\"])\n",
    "y = df[\"EngagementLevel\"]\n",
    "X = pd.get_dummies(X, columns=['Gender', 'Location', 'GameGenre', 'GameDifficulty'], drop_first=True)\n",
    "\n",
    "print(X.columns)\n",
    "print(X.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76692771",
   "metadata": {},
   "source": [
    "# Arbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a4049e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.72%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Visualizar el árbol de decisión\u001b[39;00m\n\u001b[32m     28\u001b[39m plt.figure(figsize=(\u001b[32m25\u001b[39m, \u001b[32m15\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m tree.plot_tree(model, filled=\u001b[38;5;28;01mTrue\u001b[39;00m, feature_names=\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m, class_names=[\u001b[33m'\u001b[39m\u001b[33mBajo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMedio\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAlto\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Crear el clasificador de árbol de decisión\u001b[39;00m\n\u001b[32m     32\u001b[39m model = DecisionTreeClassifier(random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo de árbol de decisión\n",
    "model = DecisionTreeClassifier( criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    min_samples_split=4,\n",
    "    splitter='random',\n",
    "    random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Visualizar el árbol de decisión\n",
    "plt.figure(figsize=(25, 15))\n",
    "tree.plot_tree(model, filled=True, feature_names=X.columns, class_names=['Bajo', 'Medio', 'Alto'])\n",
    "\n",
    "# Crear el clasificador de árbol de decisión\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Definir el grid de parámetros\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best' , 'random']\n",
    "}\n",
    "\n",
    "# Crear el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Ajustar el modelo con los parámetros especificados\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ver los mejores parámetros encontrados\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(f\"Accuracy en el conjunto de prueba: {accuracy:.4f}\")\n",
    "\n",
    "# Crear el modelo con los mejores parámetros\n",
    "best_model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=2,\n",
    "    splitter='best',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el conjunto de prueba\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo optimizado\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Accuracy con modelo optimizado: {accuracy_best * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
